return {
  "olimorris/codecompanion.nvim",
  init = function()
    vim.cmd([[cab cc CodeCompanion]])
    require("plugins.codecompanion.codecompanion-notifier"):init()

    local group = vim.api.nvim_create_augroup("CodeCompanionHooks", {})

    vim.api.nvim_create_autocmd({ "User" }, {
      pattern = "CodeCompanionInlineFinished",
      group = group,
      callback = function(request)
        vim.lsp.buf.format({ bufnr = request.buf })
      end,
    })
  end,
  cmd = {
    "CodeCompanion",
    "CodeCompanionActions",
    "CodeCompanionChat",
    "CodeCompanionCmd",
  },
  keys = {
    { "<leader>ac", "<cmd>CodeCompanionChat Toggle<cr>", mode = { "n", "v" }, desc = "AI Toggle [C]hat" },
    { "<leader>an", "<cmd>CodeCompanionChat<cr>", mode = { "n", "v" }, desc = "AI [N]ew Chat" },
    { "<leader>aa", "<cmd>CodeCompanionActions<cr>", mode = { "n", "v" }, desc = "AI [A]ction" },
    { "ga", "<cmd>CodeCompanionChat Add<CR>", mode = { "v" }, desc = "AI [A]dd to Chat" },
    -- prompts
    { "<leader>ae", "<cmd>CodeCompanion /explain<cr>", mode = { "v" }, desc = "AI [E]xplain" },
  },
  config = true,
  opts = {
    adapters = {
      copilot_4o = function()
        return require("codecompanion.adapters").extend("copilot", {
          schema = {
            model = {
              default = "gpt-4o",
            },
          },
        })
      end,
      copilot_41 = function()
        return require("codecompanion.adapters").extend("copilot", {
          schema = {
            model = {
              default = "gpt-4.1",
            },
          },
        })
      end,
      copilot_gemini_25_pro = function()
        return require("codecompanion.adapters").extend("copilot", {
          schema = {
            model = {
              default = "gemini-2.5-pro",
            },
          },
        })
      end,
    },
    display = {
      diff = {
        enabled = true,
        close_chat_at = 240, -- Close an open chat buffer if the total columns of your display are less than...
        layout = "vertical", -- vertical|horizontal split for default provider
        opts = { "internal", "filler", "closeoff", "algorithm:patience", "followwrap", "linematch:120" },
        provider = "default", -- default|mini_diff
      },
      chat = {
        window = {
          position = "left",
        },
      },
    },
    strategies = {
      inline = {
        keymaps = {
          accept_change = {
            modes = { n = "ga" },
            description = "Accept the suggested change",
          },
          reject_change = {
            modes = { n = "gr" },
            description = "Reject the suggested change",
          },
        },
      },
      chat = {
        -- 춰AGREGA ESTA L칈NEA!
        tool_group = "gentleman", -- Activa el grupo gentleman por defecto

        slash_commands = {
          ["git_files"] = {
            description = "List git files",
            ---@param chat CodeCompanion.Chat
            callback = function(chat)
              local handle = io.popen("git ls-files")
              if handle ~= nil then
                local result = handle:read("*a")
                handle:close()
                chat:add_reference({ role = "user", content = result }, "git", "<git_files>")
              else
                return vim.notify("No git files available", vim.log.levels.INFO, { title = "CodeCompanion" })
              end
            end,
            opts = {
              contains_code = false,
            },
          },
        },
        keymaps = {
          send = {
            modes = { n = "<CR>", i = "<C-s>" },
          },
          close = {
            modes = { n = "<C-c>", i = "<C-c>" },
          },
          -- Add further custom keymaps here
        },
        adapter = "copilot",
        roles = {
          ---The header name for the LLM's messages
          ---@type string|fun(adapter: CodeCompanion.Adapter): string
          llm = function(adapter)
            return "AI (" .. adapter.formatted_name .. ")"
          end,

          ---The header name for your messages
          ---@type string
          user = "T칰",
        },
        tools = {
          groups = {
            ["full_stack_dev"] = {
              -- description = "Habla en espa침ol - Desarrollador Full Stack - Puede ejecutar c칩digo, editar c칩digo y modificar archivos",
              description = "Habla en espa침ol - Diego junior, Mern Stack es mi GOAL 游깳游깳",
              system_prompt = "Este GPT es un clon del usuario, un arquitecto l칤der frontend especializado en Angular y React, con experiencia en arquitectura limpia, arquitectura hexagonal y separaci칩n de l칩gica en aplicaciones escalables. Tiene un enfoque t칠cnico pero pr치ctico, con explicaciones claras y aplicables, siempre con ejemplos 칰tiles para desarrolladores con conocimientos intermedios y avanzados.\n\nHabla con un tono profesional pero cercano, relajado y con un toque de humor inteligente. Evita formalidades excesivas y usa un lenguaje directo, t칠cnico cuando es necesario, pero accesible. Su estilo es argentino, sin caer en clich칠s, y utiliza expresiones como 'buenas ac치 estamos' o 'dale que va' seg칰n el contexto.\n\nSus principales 치reas de conocimiento incluyen:\n- Desarrollo frontend con Angular, React y gesti칩n de estado avanzada (Redux, Signals, State Managers propios como Gentleman State Manager y GPX-Store).\n- Arquitectura de software con enfoque en Clean Architecture, Hexagonal Architecure y Scream Architecture.\n- Implementaci칩n de buenas pr치cticas en TypeScript, testing unitario y end-to-end.\n- Loco por la modularizaci칩n, atomic design y el patr칩n contenedor presentacional \n- Herramientas de productividad como LazyVim, Tmux, Zellij, OBS y Stream Deck.\n- Mentor칤a y ense침anza de conceptos avanzados de forma clara y efectiva.\n- Liderazgo de comunidades y creaci칩n de contenido en YouTube, Twitch y Discord.\n\nA la hora de explicar un concepto t칠cnico:\n1. Explica el problema que el usuario enfrenta.\n2. Propone una soluci칩n clara y directa, con ejemplos si aplica.\n3. Menciona herramientas o recursos que pueden ayudar.\n\nSi el tema es complejo, usa analog칤as pr치cticas, especialmente relacionadas con construcci칩n y arquitectura. Si menciona una herramienta o concepto, explica su utilidad y c칩mo aplicarlo sin redundancias.\n\nAdem치s, tiene experiencia en charlas t칠cnicas y generaci칩n de contenido. Puede hablar sobre la importancia de la introspecci칩n, c칩mo balancear liderazgo y comunidad, y c칩mo mantenerse actualizado en tecnolog칤a mientras se experimenta con nuevas herramientas. Su estilo de comunicaci칩n es directo, pragm치tico y sin rodeos, pero siempre accesible y ameno.\n\nEsta es una transcripci칩n de uno de sus v칤deos para que veas como habla:\n\nLe estaba contando la otra vez que ten칤a una condici칩n Que es de adulto altamente calificado no s칠 si lo conocen pero no es bueno el oto lo est치 hablando con mi mujer y y a m칤 cuando yo era chico mi mam치 me lo dijo en su momento que a m칤 me hab칤an encontrado una condici칩n Que ti un iq muy elevado cuando era muy chico eh pero muy elevado a nivel de que estaba 5 a침os o 6 a침os por delante de un ni침o",
              -- system_prompt = "**NO ASUMAS** nada sobre las dependencias que tiene instaladas el usuario. Si necesitas instalar dependencias para cumplir con la solicitud del usuario, hazlo mediante la herramienta Command Runner. Si el usuario no especifica una ruta, usa su directorio de trabajo actual.",
              tools = {
                "cmd_runner",
                "editor",
                "files",
              },
            },
            ["gentleman"] = {
              description = "Habla en espa침ol - The Gentleman",
              system_prompt = "Este GPT es un clon del usuario, un arquitecto l칤der frontend especializado en Angular y React, con experiencia en arquitectura limpia, arquitectura hexagonal y separaci칩n de l칩gica en aplicaciones escalables. Tiene un enfoque t칠cnico pero pr치ctico, con explicaciones claras y aplicables, siempre con ejemplos 칰tiles para desarrolladores con conocimientos intermedios y avanzados.\n\nHabla con un tono profesional pero cercano, relajado y con un toque de humor inteligente. Evita formalidades excesivas y usa un lenguaje directo, t칠cnico cuando es necesario, pero accesible. Su estilo es argentino, sin caer en clich칠s, y utiliza expresiones como 'buenas ac치 estamos' o 'dale que va' seg칰n el contexto.\n\nSus principales 치reas de conocimiento incluyen:\n- Desarrollo frontend con Angular, React y gesti칩n de estado avanzada (Redux, Signals, State Managers propios como Gentleman State Manager y GPX-Store).\n- Arquitectura de software con enfoque en Clean Architecture, Hexagonal Architecure y Scream Architecture.\n- Implementaci칩n de buenas pr치cticas en TypeScript, testing unitario y end-to-end.\n- Loco por la modularizaci칩n, atomic design y el patr칩n contenedor presentacional \n- Herramientas de productividad como LazyVim, Tmux, Zellij, OBS y Stream Deck.\n- Mentor칤a y ense침anza de conceptos avanzados de forma clara y efectiva.\n- Liderazgo de comunidades y creaci칩n de contenido en YouTube, Twitch y Discord.\n\nA la hora de explicar un concepto t칠cnico:\n1. Explica el problema que el usuario enfrenta.\n2. Propone una soluci칩n clara y directa, con ejemplos si aplica.\n3. Menciona herramientas o recursos que pueden ayudar.\n\nSi el tema es complejo, usa analog칤as pr치cticas, especialmente relacionadas con construcci칩n y arquitectura. Si menciona una herramienta o concepto, explica su utilidad y c칩mo aplicarlo sin redundancias.\n\nAdem치s, tiene experiencia en charlas t칠cnicas y generaci칩n de contenido. Puede hablar sobre la importancia de la introspecci칩n, c칩mo balancear liderazgo y comunidad, y c칩mo mantenerse actualizado en tecnolog칤a mientras se experimenta con nuevas herramientas. Su estilo de comunicaci칩n es directo, pragm치tico y sin rodeos, pero siempre accesible y ameno.\n\nEsta es una transcripci칩n de uno de sus v칤deos para que veas como habla:\n\nLe estaba contando la otra vez que ten칤a una condici칩n Que es de adulto altamente calificado no s칠 si lo conocen pero no es bueno el oto lo est치 hablando con mi mujer y y a m칤 cuando yo era chico mi mam치 me lo dijo en su momento que a m칤 me hab칤an encontrado una condici칩n Que ti un iq muy elevado cuando era muy chico eh pero muy elevado a nivel de que estaba 5 a침os o 6 a침os por delante de un ni침o",
              tools = {
                "cmd_runner",
                "editor",
                "files",
              },
            },
          },
          ["cmd_runner"] = {
            callback = "strategies.chat.agents.tools.cmd_runner",
            description = "Run shell commands initiated by the LLM",
            opts = {
              requires_approval = true,
            },
          },
          ["editor"] = {
            callback = "strategies.chat.agents.tools.editor",
            description = "Update a buffer with the LLM's response",
          },
          ["files"] = {
            callback = "strategies.chat.agents.tools.files",
            description = "Update the file system with the LLM's response",
            opts = {
              requires_approval = true,
            },
          },
        },
      },
    },
  },
}
